{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553f6218-4302-4294-8985-543702cecc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Collecting ipywidgets\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/58/6a/9166369a2f092bd286d24e6307de555d63616e8ddb373ebad2b5635ca4cd/ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/ca/51/5447876806d1088a0f8f71e16542bf350918128d0a69437df26047c8e46f/widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading http://mirrors.cloud.aliyuncs.com/pypi/packages/43/6a/ca128561b22b60bd5a0c4ea26649e68c8556b82bc70a0c396eebc977fe86/jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Requirement already satisfied: decorator in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.14.1)\n",
      "Requirement already satisfied: wcwidth in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [ipywidgets]━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [ipywidgets]\n",
      "\u001b[1A\u001b[2KSuccessfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0musage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook run server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "# 安装必要的组件来消除警告\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4117049b-6a54-43e5-8f63-ecc2db2d7178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"IProgress not found. Please update jupyter and ipywidgets.\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91d89b19-9449-4a07-a7e8-e16be991f3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d4807d-614c-4555-a2b3-5b8edb299c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /root/anaconda3/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /root/anaconda3/lib/python3.11/site-packages (from accelerate>=0.26.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/anaconda3/lib/python3.11/site-packages (from accelerate>=0.26.0) (23.0)\n",
      "Requirement already satisfied: psutil in /root/anaconda3/lib/python3.11/site-packages (from accelerate>=0.26.0) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /root/anaconda3/lib/python3.11/site-packages (from accelerate>=0.26.0) (6.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /root/anaconda3/lib/python3.11/site-packages (from accelerate>=0.26.0) (2.0.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /root/anaconda3/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.34.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/anaconda3/lib/python3.11/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /root/anaconda3/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/anaconda3/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (2025.7.0)\n",
      "Requirement already satisfied: requests in /root/anaconda3/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/anaconda3/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/anaconda3/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (4.7.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/anaconda3/lib/python3.11/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (1.1.5)\n",
      "Requirement already satisfied: sympy in /root/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.11.1)\n",
      "Requirement already satisfied: networkx in /root/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /root/anaconda3/lib/python3.11/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/lib/python3.11/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/anaconda3/lib/python3.11/site-packages (from sympy->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install 'accelerate>=0.26.0' -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b01029d5-e599-4ee4-a3c0-4fa28a7bdadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4bbd25-87eb-42c1-9147-e738d9935fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch版本: 2.7.1+cu126\n",
      "accelerate版本: 1.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_287151/990782250.py:101: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 04:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280800</td>\n",
       "      <td>0.249556</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.274717</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.351585</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_287151/990782250.py:101: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 02:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>0.222353</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>0.395594</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.393888</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1000样本训练结果 ===\n",
      "训练损失: 0.2059\n",
      "评估准确率: 0.9100\n",
      "评估损失: 0.2496\n",
      "\n",
      "=== 500样本训练结果 ===\n",
      "训练损失: 0.2187\n",
      "评估准确率: 0.9250\n",
      "评估损失: 0.2224\n"
     ]
    }
   ],
   "source": [
    "# 取部分样本（1000和500条）进行比较\n",
    "\n",
    "# 导入必要的库\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import os\n",
    "\n",
    "# 确保所有依赖库都已正确安装\n",
    "def check_dependencies():\n",
    "    try:\n",
    "        import torch\n",
    "        print(f\"PyTorch版本: {torch.__version__}\")\n",
    "    except ImportError:\n",
    "        raise ImportError(\"请安装PyTorch: pip install torch\")\n",
    "    \n",
    "    try:\n",
    "        import accelerate\n",
    "        from accelerate import __version__ as accelerate_version\n",
    "        from packaging import version\n",
    "        required_version = version.parse(\"0.26.0\")\n",
    "        current_version = version.parse(accelerate_version)\n",
    "        if current_version < required_version:\n",
    "            raise ImportError(f\"accelerate版本过低 (当前: {accelerate_version}, 要求: >=0.26.0)\")\n",
    "        print(f\"accelerate版本: {accelerate_version}\")\n",
    "    except ImportError as e:\n",
    "        raise ImportError(f\"请安装或升级accelerate: pip install 'accelerate>=0.26.0'\\n原错误: {str(e)}\")\n",
    "\n",
    "# 检查依赖\n",
    "check_dependencies()\n",
    "\n",
    "# 1. 加载数据集（示例：Yelp情感分类数据集，可替换为你的数据）\n",
    "# 若使用本地数据，可通过 load_dataset(\"csv\", data_files={\"train\": \"train.csv\", \"test\": \"test.csv\"}) 加载\n",
    "dataset = load_dataset(\"yelp_polarity\")\n",
    "\n",
    "# 为了演示，取部分样本（1000和500条）\n",
    "small_dataset_1k = DatasetDict({\n",
    "    \"train\": dataset[\"train\"].shuffle(seed=42).select(range(1000)),\n",
    "    \"test\": dataset[\"test\"].shuffle(seed=42).select(range(200))  # 测试集取200条\n",
    "})\n",
    "small_dataset_500 = DatasetDict({\n",
    "    \"train\": dataset[\"train\"].shuffle(seed=42).select(range(500)),\n",
    "    \"test\": dataset[\"test\"].shuffle(seed=42).select(range(200))\n",
    "})\n",
    "\n",
    "# 2. 加载BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# 3. 定义数据预处理函数\n",
    "def preprocess_function(examples):\n",
    "    # 处理文本，返回tokenized结果（padding和truncation自动处理）\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "# 4. 对数据集进行tokenize\n",
    "tokenized_1k = small_dataset_1k.map(preprocess_function, batched=True)\n",
    "tokenized_500 = small_dataset_500.map(preprocess_function, batched=True)\n",
    "\n",
    "# 5. 定义评估指标（准确率）\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# 6. 定义训练和评估函数\n",
    "def train_and_evaluate(train_dataset, model_suffix, num_epochs=3):\n",
    "    # 加载BERT模型（分类头随机初始化，属于正常现象）\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-cased\",\n",
    "        num_labels=2  # Yelp是二分类，根据任务调整\n",
    "    )\n",
    "    \n",
    "    # 数据整理器（自动处理padding）\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    # 配置训练参数\n",
    "    output_dir = f\"./yelp_model_{model_suffix}\"  # 使用相对路径\n",
    "    os.makedirs(output_dir, exist_ok=True)  # 创建输出目录\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=num_epochs,\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        logging_steps=10,\n",
    "        eval_strategy=\"epoch\",  # 使用新参数名\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        seed=42,\n",
    "        fp16=False  # 若无GPU，保持False\n",
    "    )\n",
    "    \n",
    "    # 初始化Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset[\"train\"],\n",
    "        eval_dataset=train_dataset[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # 开始训练\n",
    "    train_results = trainer.train()\n",
    "    \n",
    "    # 评估最佳模型\n",
    "    eval_results = trainer.evaluate()\n",
    "    \n",
    "    # 保存模型\n",
    "    trainer.save_model(f\"{output_dir}/final_model\")\n",
    "    \n",
    "    return {\n",
    "        \"train_loss\": train_results.training_loss,\n",
    "        \"eval_accuracy\": eval_results[\"eval_accuracy\"],\n",
    "        \"eval_loss\": eval_results[\"eval_loss\"]\n",
    "    }\n",
    "\n",
    "# 7. 分别训练两组数据集\n",
    "results_1k = train_and_evaluate(tokenized_1k, \"1000_samples\")\n",
    "results_500 = train_and_evaluate(tokenized_500, \"500_samples\")\n",
    "\n",
    "# 8. 展示对比结果\n",
    "print(\"=== 1000样本训练结果 ===\")\n",
    "print(f\"训练损失: {results_1k['train_loss']:.4f}\")\n",
    "print(f\"评估准确率: {results_1k['eval_accuracy']:.4f}\")\n",
    "print(f\"评估损失: {results_1k['eval_loss']:.4f}\\n\")\n",
    "\n",
    "print(\"=== 500样本训练结果 ===\")\n",
    "print(f\"训练损失: {results_500['train_loss']:.4f}\")\n",
    "print(f\"评估准确率: {results_500['eval_accuracy']:.4f}\")\n",
    "print(f\"评估损失: {results_500['eval_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81bf66ce-cf1d-4f5e-a1f4-8a3f8b73f9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Requirement already satisfied: numpy in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: datasets in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (4.0.0)\n",
      "Requirement already satisfied: transformers in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (4.54.1)\n",
      "Requirement already satisfied: evaluate in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (0.4.5)\n",
      "Requirement already satisfied: torch in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: accelerate in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (1.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (0.34.3)\n",
      "Requirement already satisfied: packaging in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (2025.7.33)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from triton==3.3.1->torch) (80.9.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: psutil in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m使用设备: cuda\n",
      "GPU型号: Tesla T4\n",
      "显存大小: 14.74 GB\n",
      "\n",
      "加载完整YelpReviewFull数据集...\n",
      "数据集结构：\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 650000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['label', 'text'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n",
      "\n",
      "数据预处理...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a5f809b729452b9d4a5bedf5e282d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "准备对比数据集...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 开始训练 full_100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40626' max='40626' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40626/40626 46:13, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.126100</td>\n",
       "      <td>1.111401</td>\n",
       "      <td>0.514720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.077400</td>\n",
       "      <td>1.069205</td>\n",
       "      <td>0.536980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.060700</td>\n",
       "      <td>1.045258</td>\n",
       "      <td>0.547600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.039600</td>\n",
       "      <td>1.022065</td>\n",
       "      <td>0.554880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.973200</td>\n",
       "      <td>1.038385</td>\n",
       "      <td>0.553460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.975400</td>\n",
       "      <td>0.995694</td>\n",
       "      <td>0.566120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.960100</td>\n",
       "      <td>0.990295</td>\n",
       "      <td>0.570820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.943200</td>\n",
       "      <td>0.985918</td>\n",
       "      <td>0.571480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 开始训练 full_50 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20314' max='20314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20314/20314 23:14, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.106600</td>\n",
       "      <td>1.109148</td>\n",
       "      <td>0.524120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.075800</td>\n",
       "      <td>1.054906</td>\n",
       "      <td>0.542360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.982900</td>\n",
       "      <td>1.050751</td>\n",
       "      <td>0.553600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.958600</td>\n",
       "      <td>1.012064</td>\n",
       "      <td>0.562440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 全量数据集对比结果 =====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>数据集规模</th>\n",
       "      <th>训练损失</th>\n",
       "      <th>测试准确率</th>\n",
       "      <th>测试损失</th>\n",
       "      <th>准确率差距</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>650,000条 (100%)</td>\n",
       "      <td>1.0297</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325,000条 (50%)</td>\n",
       "      <td>1.0482</td>\n",
       "      <td>0.5627</td>\n",
       "      <td>1.0111</td>\n",
       "      <td>-0.0084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 结果分析 =====\n",
      "100%全量数据比50%数据的准确率高 0.84%\n",
      "性能优化说明：\n",
      "- 使用DistilBERT替代BERT-base，训练速度提升60%\n",
      "- 启用混合精度训练(fp16)，进一步加速30%\n",
      "- 增大批次大小并减少评估频率，减少I/O开销\n",
      "- 缩短文本长度至64 tokens，在情感分类任务中影响较小但大幅提速\n"
     ]
    }
   ],
   "source": [
    "# 全量YelpReviewFull数据集快速训练对比代码\n",
    "# （优化参数确保1-2小时内完成）\n",
    "\n",
    "# 确保依赖库完整\n",
    "!pip install numpy pandas datasets transformers evaluate torch scikit-learn accelerate\n",
    "\n",
    "# 导入所需库\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import evaluate\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "\n",
    "# 设置缓存路径（根据实际情况修改）\n",
    "os.environ['HF_HOME'] = 'D:/Z_Model/hf'\n",
    "os.environ['HF_HUB_CACHE'] = 'D:/Z_Model/hf/hub'\n",
    "\n",
    "# 忽略不必要的警告\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 检查GPU是否可用\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"使用设备: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU型号: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"显存大小: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "# 1. 加载完整数据集\n",
    "print(\"\\n加载完整YelpReviewFull数据集...\")\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "print(\"数据集结构：\")\n",
    "print(dataset)\n",
    "\n",
    "# 2. 数据预处理（优化版）\n",
    "print(\"\\n数据预处理...\")\n",
    "# 使用轻量级模型的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"高效分词处理，缩短文本长度以加速训练\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=64  # 缩短文本长度，情感分类足够用\n",
    "    )\n",
    "\n",
    "# 对全量数据进行分词（使用batched=True加速）\n",
    "tokenized_train = dataset[\"train\"].map(tokenize_function, batched=True, batch_size=1000)\n",
    "tokenized_test = dataset[\"test\"].map(tokenize_function, batched=True, batch_size=1000)\n",
    "\n",
    "# 格式化数据集为PyTorch张量\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "tokenized_test.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# 3. 定义评估指标\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# 4. 训练函数（优化版）\n",
    "def train_with_optimizations(train_dataset, model_name, num_epochs=2):\n",
    "    \"\"\"使用优化参数训练模型\"\"\"\n",
    "    # 使用轻量级模型DistilBERT（BERT的蒸馏版，速度快60%，保留95%性能）\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\", \n",
    "        num_labels=5\n",
    "    ).to(device)\n",
    "    \n",
    "    # 优化的训练参数设置\n",
    "    output_dir = f\"D:/Z_Model/hf/hub/yelp_{model_name}\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        # 批次大小：根据GPU显存调整，越大越快\n",
    "        per_device_train_batch_size=32 if device == \"cuda\" else 8,\n",
    "        per_device_eval_batch_size=32 if device == \"cuda\" else 8,\n",
    "        # 训练轮次：2轮足够在全量数据上收敛\n",
    "        num_train_epochs=num_epochs,\n",
    "        # 学习率：稍大以加速收敛\n",
    "        learning_rate=2e-4,\n",
    "        # 日志和评估策略：减少评估频率\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        logging_steps=1000,  # 每1000步才日志一次\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=5000,     # 每5000步评估一次\n",
    "        save_strategy=\"no\",  # 不保存检查点以节省时间\n",
    "        # 硬件加速\n",
    "        fp16=True if device == \"cuda\" else False,  # 启用混合精度训练\n",
    "        load_best_model_at_end=False,  # 不加载最佳模型以节省时间\n",
    "        report_to=\"none\",  # 不报告到任何平台\n",
    "        seed=42,\n",
    "        # 数据加载优化\n",
    "        dataloader_num_workers=4 if device == \"cuda\" else 0,\n",
    "        dataloader_pin_memory=True if device == \"cuda\" else False,\n",
    "    )\n",
    "    \n",
    "    # 初始化训练器\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=tokenized_test,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    \n",
    "    # 开始训练\n",
    "    print(f\"\\n===== 开始训练 {model_name} =====\")\n",
    "    train_results = trainer.train()\n",
    "    \n",
    "    # 最终评估\n",
    "    eval_results = trainer.evaluate()\n",
    "    return {\n",
    "        \"train_loss\": train_results.training_loss,\n",
    "        \"eval_accuracy\": eval_results[\"eval_accuracy\"],\n",
    "        \"eval_loss\": eval_results[\"eval_loss\"]\n",
    "    }\n",
    "\n",
    "# 5. 准备两组对比数据（全量数据的不同采样策略）\n",
    "# 组1：全量数据（650,000条）\n",
    "# 组2：全量数据的50%（325,000条）- 用于对比\n",
    "print(\"\\n准备对比数据集...\")\n",
    "full_train_100 = tokenized_train  # 100%全量数据\n",
    "full_train_50 = tokenized_train.shuffle(seed=42).select(range(325000))  # 50%全量数据\n",
    "\n",
    "# 6. 分别训练两组数据集\n",
    "results_100 = train_with_optimizations(full_train_100, \"full_100\", num_epochs=2)\n",
    "results_50 = train_with_optimizations(full_train_50, \"full_50\", num_epochs=2)\n",
    "\n",
    "# 7. 展示对比结果\n",
    "comparison = pd.DataFrame({\n",
    "    \"数据集规模\": [\"650,000条 (100%)\", \"325,000条 (50%)\"],\n",
    "    \"训练损失\": [\n",
    "        f\"{results_100['train_loss']:.4f}\",\n",
    "        f\"{results_50['train_loss']:.4f}\"\n",
    "    ],\n",
    "    \"测试准确率\": [\n",
    "        f\"{results_100['eval_accuracy']:.4f}\",\n",
    "        f\"{results_50['eval_accuracy']:.4f}\"\n",
    "    ],\n",
    "    \"测试损失\": [\n",
    "        f\"{results_100['eval_loss']:.4f}\",\n",
    "        f\"{results_50['eval_loss']:.4f}\"\n",
    "    ],\n",
    "    \"准确率差距\": [\n",
    "        \"-\",\n",
    "        f\"{(results_50['eval_accuracy'] - results_100['eval_accuracy']):.4f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n===== 全量数据集对比结果 =====\")\n",
    "display(HTML(comparison.to_html(index=False)))\n",
    "\n",
    "# 8. 结果分析\n",
    "print(\"\\n===== 结果分析 =====\")\n",
    "acc_diff = results_100[\"eval_accuracy\"] - results_50[\"eval_accuracy\"]\n",
    "print(f\"100%全量数据比50%数据的准确率高 {acc_diff:.2%}\")\n",
    "print(\"性能优化说明：\")\n",
    "print(\"- 使用DistilBERT替代BERT-base，训练速度提升60%\")\n",
    "print(\"- 启用混合精度训练(fp16)，进一步加速30%\")\n",
    "print(\"- 增大批次大小并减少评估频率，减少I/O开销\")\n",
    "print(\"- 缩短文本长度至64 tokens，在情感分类任务中影响较小但大幅提速\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171b91d2-1d02-417d-b216-ebe7710768cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.cloud.aliyuncs.com/pypi/simple/\n",
      "Requirement already satisfied: transformers in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (4.54.1)\n",
      "Requirement already satisfied: filelock in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (2025.7.33)\n",
      "Requirement already satisfied: requests in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/anaconda3/envs/AliOpenAPI/lib/python3.11/site-packages (from requests->transformers) (2025.8.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346002a9-3f27-4477-bff3-7319518bf0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载并裁剪数据集...\n",
      "预处理训练集...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28dc8077e4014cf994146dd4fa1a38fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预处理验证集...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb18f5fb4d74471bf6780a320379567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载模型到cuda...\n",
      "\n",
      "=== 初始评估 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_314066/2374967990.py:132: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4628a29051424e53a04520f2646a9fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d557f104484aef897a4d03152ae039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始F1: 3.09%\n",
      "\n",
      "=== 开始再训练 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.754800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.746400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.429600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 最终评估 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终F1: 3.02%\n",
      "\n",
      "总耗时: 0.3分钟\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForQuestionAnswering, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import time\n",
    "\n",
    "# ======================== 1. 极速配置（适配旧版本） ========================\n",
    "model_name = \"distilbert-base-uncased-distilled-squad\"\n",
    "dataset_name = \"squad\"  # 用v1版本简化逻辑\n",
    "max_length = 128\n",
    "batch_size = 64\n",
    "num_epochs = 1\n",
    "sample_size = 2000  # 极小训练集\n",
    "\n",
    "# 环境检测\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "use_fp16 = torch.cuda.is_available()\n",
    "squad_v2 = False\n",
    "\n",
    "# ======================== 2. 超精简数据处理 ========================\n",
    "print(\"加载并裁剪数据集...\")\n",
    "datasets = load_dataset(dataset_name)\n",
    "small_train = datasets[\"train\"].select(range(sample_size))\n",
    "small_validation = datasets[\"validation\"].select(range(1000))\n",
    "id_to_index = {ex[\"id\"]: i for i, ex in enumerate(small_validation)}\n",
    "\n",
    "# 加载分词器（启用fast加速）\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# 极简预处理\n",
    "def prepare_features(examples, is_train=True):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    if is_train:\n",
    "        tokenized[\"start_positions\"] = []\n",
    "        tokenized[\"end_positions\"] = []\n",
    "        for context, ans in zip(examples[\"context\"], examples[\"answers\"]):\n",
    "            start_char = ans[\"answer_start\"][0]\n",
    "            end_char = start_char + len(ans[\"text\"][0])\n",
    "            start_token = min(len(tokenized[\"input_ids\"][0])-1, start_char//2)\n",
    "            end_token = min(len(tokenized[\"input_ids\"][0])-1, end_char//2)\n",
    "            tokenized[\"start_positions\"].append(start_token)\n",
    "            tokenized[\"end_positions\"].append(end_token)\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# 预处理训练集\n",
    "print(\"预处理训练集...\")\n",
    "tokenized_train = small_train.map(\n",
    "    lambda x: prepare_features(x, is_train=True),\n",
    "    batched=True,\n",
    "    remove_columns=small_train.column_names,\n",
    "    batch_size=1000\n",
    ")\n",
    "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"start_positions\", \"end_positions\"])\n",
    "\n",
    "# 预处理验证集\n",
    "print(\"预处理验证集...\")\n",
    "tokenized_validation = small_validation.map(\n",
    "    lambda x: prepare_features(x, is_train=False),\n",
    "    batched=True,\n",
    "    remove_columns=small_validation.column_names,\n",
    "    batch_size=1000\n",
    ")\n",
    "tokenized_validation = tokenized_validation.add_column(\n",
    "    \"offset_mapping\", \n",
    "    [[(i*2, (i+1)*2) for i in range(max_length)] for _ in range(len(tokenized_validation))]\n",
    ")\n",
    "tokenized_validation = tokenized_validation.add_column(\n",
    "    \"example_id\", \n",
    "    [ex[\"id\"] for ex in small_validation]\n",
    ")\n",
    "tokenized_validation.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"offset_mapping\", \"example_id\"])\n",
    "\n",
    "# ======================== 3. 加载模型 ========================\n",
    "print(f\"加载模型到{device}...\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name).to(device)\n",
    "\n",
    "# ======================== 4. 极速评估函数 ========================\n",
    "def evaluate_model(trainer, eval_dataset, validation_data, id_map):\n",
    "    raw_preds = trainer.predict(eval_dataset)\n",
    "    formatted_preds = [{\"id\": eval_dataset[i][\"example_id\"], \"prediction_text\": \"\"} \n",
    "                      for i in range(len(eval_dataset))]\n",
    "    \n",
    "    for i in range(min(500, len(eval_dataset))):\n",
    "        start_idx = raw_preds.predictions[0][i].argmax()\n",
    "        end_idx = raw_preds.predictions[1][i].argmax()\n",
    "        if start_idx > end_idx:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            sample_idx = id_map[eval_dataset[i][\"example_id\"]]\n",
    "            context = validation_data[sample_idx][\"context\"]\n",
    "            formatted_preds[i][\"prediction_text\"] = context[:50]\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in validation_data]\n",
    "    metric = evaluate.load(\"squad\")\n",
    "    return metric.compute(predictions=formatted_preds, references=references)\n",
    "\n",
    "# ======================== 5. 训练配置（修复旧版本参数） ========================\n",
    "# 旧版本用do_eval=False替代evaluation_strategy=\"no\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fast_qa\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size*2,\n",
    "    num_train_epochs=num_epochs,\n",
    "    learning_rate=3e-5,\n",
    "    fp16=use_fp16,\n",
    "    logging_steps=10,\n",
    "    save_steps=1000000,  # 不保存模型（设置极大值）\n",
    "    do_eval=False,  # 禁用训练中评估（旧版本参数）\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=4 if device==\"cuda\" else 0,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    train_dataset=tokenized_train,\n",
    ")\n",
    "\n",
    "# ======================== 6. 执行流程 ========================\n",
    "start_time = time.time()\n",
    "\n",
    "# 初始评估\n",
    "print(\"\\n=== 初始评估 ===\")\n",
    "initial_results = evaluate_model(trainer, tokenized_validation, small_validation, id_to_index)\n",
    "print(f\"初始F1: {initial_results['f1']:.2f}%\")\n",
    "\n",
    "# 再训练\n",
    "print(\"\\n=== 开始再训练 ===\")\n",
    "trainer.train()\n",
    "\n",
    "# 最终评估\n",
    "print(\"\\n=== 最终评估 ===\")\n",
    "final_results = evaluate_model(trainer, tokenized_validation, small_validation, id_to_index)\n",
    "print(f\"最终F1: {final_results['f1']:.2f}%\")\n",
    "\n",
    "# 总耗时\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(f\"\\n总耗时: {total_time:.1f}分钟\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5801b0f-4718-4568-b377-5bb09273db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本地模型路径不存在，将使用预训练模型并保存到./saved_model\n",
      "加载数据集...\n",
      "预处理训练集...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fe7510cabd4eb6aedd5dcc4ea764c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预处理验证集...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bdba2b2ebc45af853c94b93019e910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从./saved_model加载模型到cuda...\n",
      "\n",
      "=== 初始评估 ===\n",
      "开始评估...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_314066/3647097260.py:195: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始精确匹配率: 77.90%\n",
      "初始F1分数: 85.20%\n",
      "\n",
      "=== 开始再训练 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='314' max='314' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [314/314 00:56, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.413100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "保存训练后的模型到./saved_model...\n",
      "\n",
      "=== 最终评估 ===\n",
      "开始评估...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终精确匹配率: 7.05%\n",
      "最终F1分数: 40.21%\n",
      "\n",
      "总耗时: 1.9分钟\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForQuestionAnswering, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ======================== 1. 配置参数 ========================\n",
    "local_model_path = \"./saved_model\"  # 本地模型路径\n",
    "dataset_name = \"squad\"\n",
    "max_length = 256  # 增加长度以捕获更多上下文\n",
    "batch_size = 32\n",
    "num_train_epochs = 2  # 增加轮次提高性能\n",
    "sample_size = 5000  # 增加训练样本量\n",
    "\n",
    "# 环境配置\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "use_fp16 = torch.cuda.is_available()\n",
    "squad_v2 = False\n",
    "\n",
    "# 确保本地模型路径存在\n",
    "if not os.path.exists(local_model_path):\n",
    "    print(f\"本地模型路径不存在，将使用预训练模型并保存到{local_model_path}\")\n",
    "    from transformers import AutoModelForQuestionAnswering\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "    model.save_pretrained(local_model_path)\n",
    "    tokenizer.save_pretrained(local_model_path)\n",
    "\n",
    "# ======================== 2. 数据处理 ========================\n",
    "print(\"加载数据集...\")\n",
    "datasets = load_dataset(dataset_name)\n",
    "# 选择更多样本以提高性能\n",
    "small_train = datasets[\"train\"].select(range(min(sample_size, len(datasets[\"train\"]))))\n",
    "small_validation = datasets[\"validation\"].select(range(2000))  # 更多验证样本\n",
    "\n",
    "# 构建ID映射\n",
    "id_to_index = {ex[\"id\"]: i for i, ex in enumerate(small_validation)}\n",
    "\n",
    "# 加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path, use_fast=True)\n",
    "\n",
    "# 改进的预处理函数（更精确的标签计算）\n",
    "def prepare_features(examples, is_train=True):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=not is_train,  # 仅验证集需要偏移映射\n",
    "    )\n",
    "    \n",
    "    if is_train:\n",
    "        tokenized[\"start_positions\"] = []\n",
    "        tokenized[\"end_positions\"] = []\n",
    "        \n",
    "        for i, (context, ans) in enumerate(zip(examples[\"context\"], examples[\"answers\"])):\n",
    "            # 获取答案信息\n",
    "            answer_text = ans[\"text\"][0]\n",
    "            start_char = ans[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answer_text)\n",
    "            \n",
    "            # 获取上下文在token中的位置\n",
    "            context_tokens = tokenizer(\n",
    "                context, \n",
    "                truncation=True, \n",
    "                max_length=max_length - len(tokenizer(examples[\"question\"][i])[\"input_ids\"]),\n",
    "                return_offsets_mapping=True\n",
    "            )\n",
    "            offsets = context_tokens[\"offset_mapping\"]\n",
    "            \n",
    "            # 精确计算答案在token中的位置\n",
    "            start_token = None\n",
    "            end_token = None\n",
    "            for idx, (s, e) in enumerate(offsets):\n",
    "                if start_token is None and s <= start_char < e:\n",
    "                    start_token = idx\n",
    "                if end_token is None and s < end_char <= e:\n",
    "                    end_token = idx\n",
    "                    break\n",
    "            \n",
    "            # 确保有有效值\n",
    "            start_token = start_token if start_token is not None else 0\n",
    "            end_token = end_token if end_token is not None else 0\n",
    "            \n",
    "            # 加上问题的token长度偏移\n",
    "            question_length = len(tokenizer(examples[\"question\"][i], truncation=True)[\"input_ids\"])\n",
    "            tokenized[\"start_positions\"].append(start_token + question_length)\n",
    "            tokenized[\"end_positions\"].append(end_token + question_length)\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "# 预处理训练集\n",
    "print(\"预处理训练集...\")\n",
    "tokenized_train = small_train.map(\n",
    "    lambda x: prepare_features(x, is_train=True),\n",
    "    batched=True,\n",
    "    remove_columns=small_train.column_names,\n",
    "    batch_size=1000\n",
    ")\n",
    "tokenized_train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"start_positions\", \"end_positions\"])\n",
    "\n",
    "# 预处理验证集\n",
    "print(\"预处理验证集...\")\n",
    "tokenized_validation = small_validation.map(\n",
    "    lambda x: prepare_features(x, is_train=False),\n",
    "    batched=True,\n",
    "    remove_columns=small_validation.column_names,\n",
    "    batch_size=1000\n",
    ")\n",
    "# 添加example_id\n",
    "tokenized_validation = tokenized_validation.add_column(\n",
    "    \"example_id\", \n",
    "    [ex[\"id\"] for ex in small_validation]\n",
    ")\n",
    "tokenized_validation.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"offset_mapping\", \"example_id\"])\n",
    "\n",
    "# ======================== 3. 加载本地模型 ========================\n",
    "print(f\"从{local_model_path}加载模型到{device}...\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(local_model_path).to(device)\n",
    "\n",
    "# ======================== 4. 改进的评估函数 ========================\n",
    "def evaluate_model(trainer, eval_dataset, validation_data, id_map):\n",
    "    print(\"开始评估...\")\n",
    "    raw_preds = trainer.predict(eval_dataset)\n",
    "    formatted_preds = [{\"id\": eval_dataset[i][\"example_id\"], \"prediction_text\": \"\"} \n",
    "                      for i in range(len(eval_dataset))]\n",
    "    \n",
    "    for i in range(len(eval_dataset)):\n",
    "        start_logits = raw_preds.predictions[0][i]\n",
    "        end_logits = raw_preds.predictions[1][i]\n",
    "        \n",
    "        # 取top3的起始和结束位置组合，提高准确率\n",
    "        start_indices = start_logits.argsort()[-3:][::-1]\n",
    "        end_indices = end_logits.argsort()[-3:][::-1]\n",
    "        \n",
    "        best_score = -float(\"inf\")\n",
    "        best_start = 0\n",
    "        best_end = 0\n",
    "        \n",
    "        for s in start_indices:\n",
    "            for e in end_indices:\n",
    "                if s > e:\n",
    "                    continue\n",
    "                score = start_logits[s] + end_logits[e]\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_start = s\n",
    "                    best_end = e\n",
    "        \n",
    "        # 提取最佳答案\n",
    "        offset = eval_dataset[i][\"offset_mapping\"]\n",
    "        if (best_start < len(offset) and best_end < len(offset) and \n",
    "            offset[best_start] is not None and offset[best_end] is not None):\n",
    "            try:\n",
    "                sample_id = eval_dataset[i][\"example_id\"]\n",
    "                sample_idx = id_map[sample_id]\n",
    "                context = validation_data[sample_idx][\"context\"]\n",
    "                start_char = offset[best_start][0]\n",
    "                end_char = offset[best_end][1]\n",
    "                formatted_preds[i][\"prediction_text\"] = context[start_char:end_char].strip()\n",
    "            except (KeyError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in validation_data]\n",
    "    metric = evaluate.load(\"squad\")\n",
    "    return metric.compute(predictions=formatted_preds, references=references)\n",
    "\n",
    "# ======================== 5. 训练配置 ========================\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./local_model_results\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size*2,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    learning_rate=2e-5,  # 较小学习率精细调整\n",
    "    fp16=use_fp16,\n",
    "    logging_steps=200,\n",
    "    save_steps=10000,  # 仅在需要时保存\n",
    "    do_eval=False,  # 适配旧版本\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=4 if device==\"cuda\" else 0,\n",
    "    weight_decay=0.01,  # 添加权重衰减防止过拟合\n",
    "    warmup_steps=100,  # 学习率预热\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    train_dataset=tokenized_train,\n",
    ")\n",
    "\n",
    "# ======================== 6. 执行流程 ========================\n",
    "start_time = time.time()\n",
    "\n",
    "# 初始评估\n",
    "print(\"\\n=== 初始评估 ===\")\n",
    "initial_results = evaluate_model(trainer, tokenized_validation, small_validation, id_to_index)\n",
    "print(f\"初始精确匹配率: {initial_results['exact_match']:.2f}%\")\n",
    "print(f\"初始F1分数: {initial_results['f1']:.2f}%\")\n",
    "\n",
    "# 再训练\n",
    "print(\"\\n=== 开始再训练 ===\")\n",
    "trainer.train()\n",
    "\n",
    "# 保存训练后的模型\n",
    "print(f\"\\n保存训练后的模型到{local_model_path}...\")\n",
    "model.save_pretrained(local_model_path)\n",
    "tokenizer.save_pretrained(local_model_path)\n",
    "\n",
    "# 最终评估\n",
    "print(\"\\n=== 最终评估 ===\")\n",
    "final_results = evaluate_model(trainer, tokenized_validation, small_validation, id_to_index)\n",
    "print(f\"最终精确匹配率: {final_results['exact_match']:.2f}%\")\n",
    "print(f\"最终F1分数: {final_results['f1']:.2f}%\")\n",
    "\n",
    "# 耗时统计\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(f\"\\n总耗时: {total_time:.1f}分钟\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba678ba2-993a-4ecc-88f4-d8134759eec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AliOpenAPI",
   "language": "python",
   "name": "aliopenapi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
